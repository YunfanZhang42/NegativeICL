## GPT-3.5, 2 Positive Examples, 0 Negative Examples

```text
************************************************************
Results for gpt-3.5-pos-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 19.804359802790522
ROUGE-1: 52.09450420286193
ROUGE-2: 32.409964820566785
ROUGE-L: 50.55339503044378
chrF: 49.824794681081336
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 90.2
ROUGE-2: 0.0
ROUGE-L: 90.2
chrF: 70.48727078720916
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 5.326880582760558
ROUGE-1: 61.6459681260765
ROUGE-2: 4.254358974358975
ROUGE-L: 61.61986406389829
chrF: 53.548839699450276
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 51.507289718828034
ROUGE-2: 0.23589743589743592
ROUGE-L: 51.512769765097545
chrF: 57.0839536268979
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 35.15937412712028
ROUGE-1: 61.72932448092836
ROUGE-2: 40.68721812864907
ROUGE-L: 56.967587440610465
chrF: 55.53115373529786
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 30.145677898565516
ROUGE-1: 63.86207114888296
ROUGE-2: 40.52719588047719
ROUGE-L: 60.75410568389367
chrF: 58.71827402207036
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 19.53302841364162
ROUGE-1: 55.227558986013356
ROUGE-2: 28.339582782120253
ROUGE-L: 42.344810575807955
chrF: 52.37102900038474
--------------------------------------------
============================================================
Average BLEU: 15.709902974982642
Average ROUGE-1: 62.32381666622731
Average ROUGE-2: 20.92203114600996
Average ROUGE-L: 59.13607607996453
Average chrF: 56.795045078913084
============================================================
Average BLEU without subtask 022: 18.32822013747975
Average ROUGE-1 without subtask 022: 57.67778611059853
Average ROUGE-2 without subtask 022: 24.409036337011617
Average ROUGE-L without subtask 022: 53.95875542662529
Average chrF without subtask 022: 54.51300746086374
************************************************************
```

## GPT-3.5, 2 Positive Examples, 2 Negative Examples
 
```text
************************************************************
Press Enter to continue to gpt-3.5-pos-2-neg-2.json...
************************************************************
Results for gpt-3.5-pos-2-neg-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 19.825340765265008
ROUGE-1: 51.982716920891484
ROUGE-2: 32.50149189179109
ROUGE-L: 50.448765813373896
chrF: 50.16701356670122
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 86.0
ROUGE-2: 0.0
ROUGE-L: 86.0
chrF: 64.91319434765617
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 6.033671050877528
ROUGE-1: 61.094458659189435
ROUGE-2: 4.271794871794872
ROUGE-L: 61.06474517988823
chrF: 53.28238237506492
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 51.27843267843251
ROUGE-2: 0.23076923076923075
ROUGE-L: 51.26988733488717
chrF: 57.80586597339891
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 36.03044236319599
ROUGE-1: 62.36258904017921
ROUGE-2: 41.39996850228351
ROUGE-L: 57.57473327258715
chrF: 55.89887983623175
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 28.830651428811844
ROUGE-1: 58.01355466643383
ROUGE-2: 36.974507877690414
ROUGE-L: 55.36140115136974
chrF: 54.221394171917034
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 17.677437164726445
ROUGE-1: 52.32391467862446
ROUGE-2: 24.895403976748614
ROUGE-L: 39.45036385000432
chrF: 50.70202467720243
--------------------------------------------
============================================================
Average BLEU: 15.485363253268115
Average ROUGE-1: 60.436523806250136
Average ROUGE-2: 20.039133764439676
Average ROUGE-L: 57.309985228872925
Average chrF: 55.28439356402463
============================================================
Average BLEU without subtask 022: 18.0662571288128
Average ROUGE-1 without subtask 022: 56.17594444062516
Average ROUGE-2 without subtask 022: 23.37898939184629
Average ROUGE-L without subtask 022: 52.52831610035175
Average chrF without subtask 022: 53.67959343341937
************************************************************
```


## Bart, Full Prompt, No Few-Shot Examples

```text
************************************************************
Results for bart-large-no-few-shot.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.778271518359347
ROUGE-1: 55.13534389522452
ROUGE-2: 35.06378428928274
ROUGE-L: 54.07968058084144
chrF: 46.172079854772626
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.1884393220584934
ROUGE-1: 11.516707927400486
ROUGE-2: 0.7732762226916478
ROUGE-L: 11.522046445210535
chrF: 21.0859823829442
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.813058970629787
ROUGE-2: 0.023076923076923075
ROUGE-L: 6.794260914362571
chrF: 18.826840952667755
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 16.344392477961605
ROUGE-1: 41.93645752166648
ROUGE-2: 17.9176659265017
ROUGE-L: 38.448788837172685
chrF: 36.20413362679143
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.45097330288532644
ROUGE-1: 19.227487788044932
ROUGE-2: 4.901786193757486
ROUGE-L: 18.857432709679895
chrF: 21.549824580675974
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.3852745500505081
ROUGE-1: 14.094116773528864
ROUGE-2: 3.3599923103180265
ROUGE-L: 13.240798344792227
chrF: 10.053346835208913
--------------------------------------------
============================================================
Average BLEU: 5.878193024473611
Average ROUGE-1: 22.16045326807072
Average ROUGE-2: 8.862797409375505
Average ROUGE-L: 21.334715404579907
Average chrF: 27.569175726098813
============================================================
Average BLEU without subtask 022: 6.8578918618858795
Average ROUGE-1 without subtask 022: 24.787195479415843
Average ROUGE-2 without subtask 022: 10.339930310938088
Average ROUGE-L without subtask 022: 23.82383463867656
Average chrF without subtask 022: 25.64870137217682
************************************************************
```


## Bart, Full Prompt, 2 Positive Examples, 0 Negative Examples

```text
************************************************************
Results for bart-large-pos-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.52577656514889
ROUGE-1: 55.76396584372026
ROUGE-2: 34.64212301316363
ROUGE-L: 53.767092974457206
chrF: 49.28621540981556
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 7.8
ROUGE-2: 0.0
ROUGE-L: 7.8
chrF: 39.25350425881181
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.4721739735007247
ROUGE-1: 15.93093755585326
ROUGE-2: 1.2877438101761296
ROUGE-L: 15.958994717630462
chrF: 23.87563696826937
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 2.903543501165553
ROUGE-2: 0.0
ROUGE-L: 2.8995033875124387
chrF: 11.204843393838814
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 19.423496749110587
ROUGE-1: 45.34713271421899
ROUGE-2: 21.10436560519204
ROUGE-L: 41.5090122901783
chrF: 40.75577113221842
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.46073479768568404
ROUGE-1: 15.550147361931078
ROUGE-2: 4.167171229665587
ROUGE-L: 15.00647500112611
chrF: 15.644540560604808
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.4947991482389986
ROUGE-1: 16.077374606399385
ROUGE-2: 3.918000131784628
ROUGE-L: 15.573009135161334
chrF: 12.368201987322799
--------------------------------------------
============================================================
Average BLEU: 6.339568747669269
Average ROUGE-1: 22.76758594046979
Average ROUGE-2: 9.302771969997432
Average ROUGE-L: 21.787726786580837
Average chrF: 27.484101958697373
============================================================
Average BLEU without subtask 022: 7.39616353894748
Average ROUGE-1 without subtask 022: 25.262183597214754
Average ROUGE-2 without subtask 022: 10.853233964997003
Average ROUGE-L without subtask 022: 24.11901458434431
Average chrF without subtask 022: 25.5225349086783
************************************************************
```


## Bart, Full Prompt, 4 Positive Examples, 0 Negative Examples

```text
************************************************************
Press Enter to continue to bart-large-pos-4.json...
************************************************************
Results for bart-large-pos-4.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.325000562965712
ROUGE-1: 54.30851114781745
ROUGE-2: 33.88185700372605
ROUGE-L: 52.780218017507096
chrF: 47.78985089588514
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.7975203190145913
ROUGE-1: 21.298868306552972
ROUGE-2: 1.942629008237272
ROUGE-L: 21.322238029524915
chrF: 26.790457782686968
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 3.481941403176218
ROUGE-2: 0.0
ROUGE-L: 3.4685410372353678
chrF: 11.51221616011251
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 18.672021212652467
ROUGE-1: 41.13693356987164
ROUGE-2: 19.18962349351931
ROUGE-L: 37.95865204345571
chrF: 36.917219704338514
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.2215073140115792
ROUGE-1: 7.364793825615908
ROUGE-2: 1.9210029737746122
ROUGE-L: 7.2082319908499715
chrF: 7.815692891730571
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.5076879859720698
ROUGE-1: 16.211856548248868
ROUGE-2: 4.403596991890854
ROUGE-L: 15.563123457794296
chrF: 12.080956670048062
--------------------------------------------
============================================================
Average BLEU: 6.217676770659489
Average ROUGE-1: 21.457557828754723
Average ROUGE-2: 8.762672781592585
Average ROUGE-L: 20.671572082338194
Average chrF: 25.99977370777608
============================================================
Average BLEU without subtask 022: 7.253956232436071
Average ROUGE-1 without subtask 022: 23.967150800213844
Average ROUGE-2 without subtask 022: 10.22311824519135
Average ROUGE-L without subtask 022: 23.05016742939456
Average chrF without subtask 022: 23.8177323508003
************************************************************
```


## Bart, Full Prompt, 2 Positive Examples, 2 Negative Examples

```text
************************************************************
Results for bart-large-pos-2-neg-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 26.24246050892976
ROUGE-1: 56.103859569494794
ROUGE-2: 36.125259017239074
ROUGE-L: 54.96422254861181
chrF: 48.59573121172258
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 93.4
ROUGE-2: 0.0
ROUGE-L: 93.4
chrF: 91.28780555512257
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.3132479455548953
ROUGE-1: 14.04030676712282
ROUGE-2: 1.1768956256785752
ROUGE-L: 14.03930795340794
chrF: 22.018386028477668
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 5.077847892142007
ROUGE-2: 0.005128205128205128
ROUGE-L: 5.081547511920222
chrF: 14.244685628403586
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 11.269994564380738
ROUGE-1: 36.32055913212613
ROUGE-2: 13.165180881258042
ROUGE-L: 33.17653371399449
chrF: 29.353717326266647
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 5.274694450491923
ROUGE-2: 1.4598809599364788
ROUGE-L: 5.264906139253592
chrF: 4.772800869459587
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.8044569313225207
ROUGE-1: 16.182896984311597
ROUGE-2: 4.581065493607851
ROUGE-L: 15.400223598121588
chrF: 13.00660302258844
--------------------------------------------
============================================================
Average BLEU: 5.518594278598274
Average ROUGE-1: 32.34288068509847
Average ROUGE-2: 8.073344311835461
Average ROUGE-L: 31.618105923615666
Average chrF: 31.897104234577302
============================================================
Average BLEU without subtask 022: 6.438359991697986
Average ROUGE-1 without subtask 022: 22.166694132614882
Average ROUGE-2 without subtask 022: 9.41890169714137
Average ROUGE-L without subtask 022: 21.321123577551607
Average chrF without subtask 022: 21.99865401448642
************************************************************
```


## Bart (All Task), Full Prompt, No Few-Shot Examples

```text
************************************************************
Results for bart-large-all-tasks-no-few-shot.json
--------------------------------------------
subtask002_quoref_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 22.63549551007836
ROUGE-1: 38.18830232659831
ROUGE-2: 17.70853142553849
ROUGE-L: 38.14487516017988
chrF: 45.15857260986038
--------------------------------------------
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 12.027645923301982
ROUGE-1: 28.8552328282734
ROUGE-2: 13.459538483474379
ROUGE-L: 27.658264545924787
chrF: 31.95837707813276
--------------------------------------------
--------------------------------------------
subtask005_mctaco_wrong_answer_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 4.933512224209898
ROUGE-2: 0.23255813953488372
ROUGE-L: 4.8458556946929034
chrF: 7.85310973113391
--------------------------------------------
--------------------------------------------
subtask008_mctaco_wrong_answer_generation_transient_stationary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 23.16291978223796
ROUGE-2: 0.0
ROUGE-L: 22.86128328741965
chrF: 6.9343335910728
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.8811355328332863
ROUGE-1: 19.717043076339756
ROUGE-2: 1.5256123306914309
ROUGE-L: 19.669745307515612
chrF: 27.497481349688012
--------------------------------------------
--------------------------------------------
subtask034_winogrande_question_modification_object
--------------------------------------------
--------------------------------------------
BLEU: 26.486506736456228
ROUGE-1: 60.965032913768155
ROUGE-2: 37.06137092384642
ROUGE-L: 51.98749101174624
chrF: 52.099866369750956
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 7.705024917357231
ROUGE-2: 0.04223387723387724
ROUGE-L: 7.700306594876344
chrF: 20.539906150858553
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 15.127423839798427
ROUGE-1: 39.35089380140716
ROUGE-2: 15.64641370577419
ROUGE-L: 35.650365936821096
chrF: 35.450568031517754
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 4.422728621672137
ROUGE-2: 1.1402206060911233
ROUGE-L: 4.343950243446688
chrF: 5.422459399543101
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.3499687992827549
ROUGE-1: 14.164010592148198
ROUGE-2: 3.346345440878542
ROUGE-L: 13.41432745090013
chrF: 10.379754259650332
--------------------------------------------
--------------------------------------------
subtask052_multirc_identify_bad_question
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 9.294871794871796
ROUGE-2: 0.0
ROUGE-L: 9.294871794871796
chrF: 41.74860813592451
--------------------------------------------
============================================================
Average BLEU: 6.45901469514592
Average ROUGE-1: 21.42996440657367
Average ROUGE-2: 7.513568744421945
Average ROUGE-L: 20.164278085699593
Average chrF: 27.01125487973032
============================================================
Average BLEU without subtask 022: 7.0461978492500945
Average ROUGE-1 without subtask 022: 22.796324807171274
Average ROUGE-2 without subtask 022: 8.196620448460303
Average ROUGE-L without subtask 022: 21.415576093490465
Average chrF without subtask 022: 25.913003337012096
************************************************************
```


## Bart (All Task), Full Prompt, Max Positive Examples, No Negative Examples

```text
************************************************************
Results for bart-large-all-tasks-pos-max.json
--------------------------------------------
subtask002_quoref_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 17.770412609019388
ROUGE-1: 25.813559527876816
ROUGE-2: 11.355302246772823
ROUGE-L: 25.806341253562504
chrF: 32.47047705419742
--------------------------------------------
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 16.56303570097556
ROUGE-1: 46.83138212000547
ROUGE-2: 23.067149619141464
ROUGE-L: 44.81462721294906
chrF: 41.93699237035931
--------------------------------------------
--------------------------------------------
subtask005_mctaco_wrong_answer_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 3.4483293045222805
ROUGE-1: 6.162613226566712
ROUGE-2: 0.8656498540219472
ROUGE-L: 6.146505948831528
chrF: 11.994852106821153
--------------------------------------------
--------------------------------------------
subtask008_mctaco_wrong_answer_generation_transient_stationary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 18.20866948707857
ROUGE-2: 0.0
ROUGE-L: 18.25786271808999
chrF: 5.879266404448507
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
This is subtask022!!!!
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 5.279382874130533
ROUGE-1: 24.572628700390116
ROUGE-2: 1.8207685146319195
ROUGE-L: 24.56878939786972
chrF: 34.362646061593644
--------------------------------------------
--------------------------------------------
subtask034_winogrande_question_modification_object
--------------------------------------------
--------------------------------------------
BLEU: 21.09426788633253
ROUGE-1: 57.12926525470638
ROUGE-2: 30.947891208089562
ROUGE-L: 45.93032383942891
chrF: 45.81475824670194
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 14.18216646601258
ROUGE-2: 0.015384615384615385
ROUGE-L: 14.190593701170567
chrF: 22.293935912275778
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 24.253433202557485
ROUGE-1: 51.538520554174674
ROUGE-2: 26.60307577186317
ROUGE-L: 47.264613586642035
chrF: 45.977667754482866
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 0.8470798886348484
ROUGE-2: 0.14248833283685836
ROUGE-L: 0.8302206928212289
chrF: 0.4906298612288853
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.186099566798222
ROUGE-1: 8.0573579144164
ROUGE-2: 1.6855068072604447
ROUGE-L: 7.475183056466533
chrF: 6.165937431127359
--------------------------------------------
--------------------------------------------
subtask052_multirc_identify_bad_question
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 25.320512820512818
ROUGE-2: 0.0
ROUGE-L: 25.320512820512818
chrF: 49.752001826496
--------------------------------------------
============================================================
Average BLEU: 7.382913428694667
Average ROUGE-1: 23.75531299669795
Average ROUGE-2: 8.041934747500234
Average ROUGE-L: 22.250464519028743
Average chrF: 28.019265573280297
============================================================
Average BLEU without subtask 022: 8.054087376757819
Average ROUGE-1 without subtask 022: 25.33306872367049
Average ROUGE-2 without subtask 022: 8.77301972454571
Average ROUGE-L without subtask 022: 23.69141583894045
Average chrF without subtask 022: 27.012651366339345
************************************************************
```
