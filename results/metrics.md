## GPT-3.5, 2 Positive Examples, 0 Negative Examples

```text
************************************************************
Results for gpt-3.5-pos-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 19.804359802790522
ROUGE-1: 52.0274824536344
ROUGE-2: 32.32596451296956
ROUGE-L: 50.573576369908466
chrF: 49.824794681081336
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 90.2
ROUGE-2: 0.0
ROUGE-L: 90.2
chrF: 70.48727078720916
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 5.326880582760558
ROUGE-1: 61.61242435314016
ROUGE-2: 4.2374358974358985
ROUGE-L: 61.628222336060915
chrF: 53.548839699450276
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 51.49199509667106
ROUGE-2: 0.23589743589743586
ROUGE-L: 51.48825647137366
chrF: 57.0839536268979
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 35.15937412712028
ROUGE-1: 61.73403225778236
ROUGE-2: 40.70696223947711
ROUGE-L: 56.9594124307229
chrF: 55.53115373529786
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 30.145677898565516
ROUGE-1: 63.86626824842509
ROUGE-2: 40.503380529000005
ROUGE-L: 60.72373047336897
chrF: 58.71827402207036
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 19.53302841364162
ROUGE-1: 55.214533237200584
ROUGE-2: 28.30221170466256
ROUGE-L: 42.380918624787135
chrF: 52.37102900038474
--------------------------------------------
============================================================
Average BLEU: 15.709902974982642
Average ROUGE-1: 62.3066765209791
Average ROUGE-2: 20.901693188491798
Average ROUGE-L: 59.13630238660314
Average chrF: 56.795045078913084
============================================================
Average BLEU without subtask 022: 109.9693208248785
Average ROUGE-1 without subtask 022: 345.9467356468537
Average ROUGE-2 without subtask 022: 146.31185231944258
Average ROUGE-L without subtask 022: 323.754116706222
Average chrF without subtask 022: 327.0780447651824
************************************************************
```

## GPT-3.5, 2 Positive Examples, 2 Negative Examples
    
```text
************************************************************
Results for gpt-3.5-pos-2-neg-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 19.825340765265008
ROUGE-1: 51.945803863773406
ROUGE-2: 32.43897852582808
ROUGE-L: 50.444675902983334
chrF: 50.16701356670122
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 86.0
ROUGE-2: 0.0
ROUGE-L: 86.0
chrF: 64.91319434765617
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 6.033671050877528
ROUGE-1: 61.059451960036185
ROUGE-2: 4.26102564102564
ROUGE-L: 61.093510776662654
chrF: 53.28238237506492
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 51.27255910755897
ROUGE-2: 0.23443223443223443
ROUGE-L: 51.240674325674185
chrF: 57.80586597339891
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 36.03044236319599
ROUGE-1: 62.35828900797603
ROUGE-2: 41.41844520805304
ROUGE-L: 57.56044601261354
chrF: 55.89887983623175
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 28.830651428811844
ROUGE-1: 58.03039662136589
ROUGE-2: 37.00082635747904
ROUGE-L: 55.34391374025741
chrF: 54.221394171917034
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 17.677437164726445
ROUGE-1: 52.41267687315161
ROUGE-2: 24.971356632744563
ROUGE-L: 39.40821488510735
chrF: 50.70202467720243
--------------------------------------------
============================================================
Average BLEU: 15.485363253268115
Average ROUGE-1: 60.439882490551724
Average ROUGE-2: 20.046437799937515
Average ROUGE-L: 57.29877652047121
Average chrF: 55.28439356402463
============================================================
Average BLEU without subtask 022: 108.3975427728768
Average ROUGE-1 without subtask 022: 337.07917743386207
Average ROUGE-2 without subtask 022: 140.3250645995626
Average ROUGE-L without subtask 022: 315.09143564329844
Average chrF without subtask 022: 322.0775606005162
************************************************************
```


## Bart, Full Prompt, No Few-Shot Examples

```text
************************************************************
Results for bart-large-no-few-shot.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.778271518359347
ROUGE-1: 55.11382746554902
ROUGE-2: 35.04819927354674
ROUGE-L: 54.06204196652607
chrF: 46.172079854772626
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.1884393220584934
ROUGE-1: 11.516642958341588
ROUGE-2: 0.7714418970591287
ROUGE-L: 11.515422116030006
chrF: 21.0859823829442
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.798156886163525
ROUGE-2: 0.02429322813938198
ROUGE-L: 6.798139619354754
chrF: 18.826840952667755
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 16.344392477961605
ROUGE-1: 41.9324687075064
ROUGE-2: 17.9240095907597
ROUGE-L: 38.46243160912064
chrF: 36.20413362679143
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.45097330288532644
ROUGE-1: 19.23553244678269
ROUGE-2: 4.917673145557109
ROUGE-L: 18.874545818735697
chrF: 21.549824580675974
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.3852745500505081
ROUGE-1: 14.110180831657745
ROUGE-2: 3.3426792908888365
ROUGE-L: 13.234096445135043
chrF: 10.053346835208913
--------------------------------------------
============================================================
Average BLEU: 5.878193024473611
Average ROUGE-1: 22.158115613714422
Average ROUGE-2: 8.861185203707272
Average ROUGE-L: 21.33523965355746
Average chrF: 27.569175726098813
============================================================
Average BLEU without subtask 022: 41.14735117131528
Average ROUGE-1 without subtask 022: 148.70680929600096
Average ROUGE-2 without subtask 022: 62.028296425950906
Average ROUGE-L without subtask 022: 142.9466775749022
Average chrF without subtask 022: 153.89220823306093
************************************************************
```


## Bart, Full Prompt, 2 Positive Examples, 0 Negative Examples

```text
************************************************************
Results for bart-large-pos-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.52577656514889
ROUGE-1: 55.70300296134825
ROUGE-2: 34.590375019734736
ROUGE-L: 53.768002709402474
chrF: 49.28621540981556
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 7.8
ROUGE-2: 0.0
ROUGE-L: 7.8
chrF: 39.25350425881181
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.4721739735007247
ROUGE-1: 15.954710976406567
ROUGE-2: 1.2856076154749458
ROUGE-L: 15.956473402055938
chrF: 23.87563696826937
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 2.900920973459078
ROUGE-2: 0.0
ROUGE-L: 2.9077353136265964
chrF: 11.204843393838814
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 19.423496749110587
ROUGE-1: 45.37225388439675
ROUGE-2: 21.124045464296866
ROUGE-L: 41.518818073097265
chrF: 40.75577113221842
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.46073479768568404
ROUGE-1: 15.555932705468322
ROUGE-2: 4.170905898957015
ROUGE-L: 15.020730375685778
chrF: 15.644540560604808
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.4947991482389986
ROUGE-1: 16.121837487002235
ROUGE-2: 3.9395680355132474
ROUGE-L: 15.69675018931655
chrF: 12.368201987322799
--------------------------------------------
============================================================
Average BLEU: 6.339568747669269
Average ROUGE-1: 22.772665569725888
Average ROUGE-2: 9.301500290568116
Average ROUGE-L: 21.809787151883516
Average chrF: 27.484101958697373
============================================================
Average BLEU without subtask 022: 44.37698123368488
Average ROUGE-1 without subtask 022: 151.6086589880812
Average ROUGE-2 without subtask 022: 65.11050203397681
Average ROUGE-L without subtask 022: 144.8685100631846
Average chrF without subtask 022: 153.1352094520698
************************************************************
```


## Bart, Full Prompt, 4 Positive Examples, 0 Negative Examples

```text
************************************************************
Results for bart-large-pos-4.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 23.325000562965712
ROUGE-1: 54.3021820142811
ROUGE-2: 33.80933260669554
ROUGE-L: 52.81935996677278
chrF: 47.78985089588514
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 6.4
ROUGE-2: 0.0
ROUGE-L: 6.4
chrF: 39.09202184963076
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.7975203190145913
ROUGE-1: 21.296210390932643
ROUGE-2: 1.928364320162649
ROUGE-L: 21.323194553468593
chrF: 26.790457782686968
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 3.4829099589119785
ROUGE-2: 0.0
ROUGE-L: 3.485736491353897
chrF: 11.51221616011251
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 18.672021212652467
ROUGE-1: 41.157138779267875
ROUGE-2: 19.19374301701582
ROUGE-L: 37.98058068093656
chrF: 36.917219704338514
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.2215073140115792
ROUGE-1: 7.369385938296216
ROUGE-2: 1.9265315956212399
ROUGE-L: 7.188565208029046
chrF: 7.815692891730571
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.5076879859720698
ROUGE-1: 16.216008695401822
ROUGE-2: 4.424145005656015
ROUGE-L: 15.60637969760359
chrF: 12.080956670048062
--------------------------------------------
============================================================
Average BLEU: 6.217676770659489
Average ROUGE-1: 21.460547968155943
Average ROUGE-2: 8.754588077878752
Average ROUGE-L: 20.686259514023494
Average chrF: 25.99977370777608
============================================================
Average BLEU without subtask 022: 43.523737394616425
Average ROUGE-1 without subtask 022: 143.8238357770916
Average ROUGE-2 without subtask 022: 61.28211654515127
Average ROUGE-L without subtask 022: 138.40381659816444
Average chrF without subtask 022: 142.9063941048018
```


## Bart, Full Prompt, 2 Positive Examples, 2 Negative Examples

```text
************************************************************
Results for bart-large-pos-2-neg-2.json
--------------------------------------------
subtask003_mctaco_question_generation_event_duration
--------------------------------------------
--------------------------------------------
BLEU: 26.24246050892976
ROUGE-1: 56.181047645047855
ROUGE-2: 36.13151156736345
ROUGE-L: 54.984595036619034
chrF: 48.59573121172258
--------------------------------------------
--------------------------------------------
subtask022_cosmosqa_passage_inappropriate_binary
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 93.4
ROUGE-2: 0.0
ROUGE-L: 93.4
chrF: 91.28780555512257
--------------------------------------------
--------------------------------------------
subtask033_winogrande_answer_generation
--------------------------------------------
--------------------------------------------
BLEU: 0.3132479455548953
ROUGE-1: 14.049974895810163
ROUGE-2: 1.1801057024751649
ROUGE-L: 14.02523407840929
chrF: 22.018386028477668
--------------------------------------------
--------------------------------------------
subtask039_qasc_find_overlapping_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 5.080964510139906
ROUGE-2: 0.005128205128205128
ROUGE-L: 5.0790741615065205
chrF: 14.244685628403586
--------------------------------------------
--------------------------------------------
subtask040_qasc_question_generation
--------------------------------------------
--------------------------------------------
BLEU: 11.269994564380738
ROUGE-1: 36.33207170313736
ROUGE-2: 13.1618102432527
ROUGE-L: 33.19277627794713
chrF: 29.353717326266647
--------------------------------------------
--------------------------------------------
subtask044_essential_terms_identifying_essential_words
--------------------------------------------
--------------------------------------------
BLEU: 0.0
ROUGE-1: 5.303613439361724
ROUGE-2: 1.4646041705839732
ROUGE-L: 5.24863471657302
chrF: 4.772800869459587
--------------------------------------------
--------------------------------------------
subtask045_miscellaneous_sentence_paraphrasing
--------------------------------------------
--------------------------------------------
BLEU: 0.8044569313225207
ROUGE-1: 16.160671185630736
ROUGE-2: 4.613957255394291
ROUGE-L: 15.429609823591914
chrF: 13.00660302258844
--------------------------------------------
============================================================
Average BLEU: 5.518594278598274
Average ROUGE-1: 32.358334768446824
Average ROUGE-2: 8.079588163456828
Average ROUGE-L: 31.62284629923527
Average chrF: 31.897104234577302
============================================================
Average BLEU without subtask 022: 38.63015995018792
Average ROUGE-1 without subtask 022: 133.10834337912775
Average ROUGE-2 without subtask 022: 56.55711714419779
Average ROUGE-L without subtask 022: 127.95992409464688
Average chrF without subtask 022: 131.99192408691852
************************************************************
```
