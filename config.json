{
  "model_type": "facebook/bart-base",
  "model_name": "bart-base-natural-instructions",
  "load_model": null,

  "subtask_dir": "./natural-instructions-1.0/data/",
  "train_tasks": [
    "subtask001_quoref_question_generation.json",
    "subtask004_mctaco_answer_generation_event_duration.json",
    "subtask006_mctaco_question_generation_transient_stationary.json",
    "subtask007_mctaco_answer_generation_transient_stationary.json",
    "subtask009_mctaco_question_generation_event_ordering.json",
    "subtask010_mctaco_answer_generation_event_ordering.json",
    "subtask011_mctaco_wrong_answer_generation_event_ordering.json",
    "subtask012_mctaco_question_generation_absolute_timepoint.json",
    "subtask013_mctaco_answer_generation_absolute_timepoint.json",
    "subtask014_mctaco_wrong_answer_generation_absolute_timepoint.json",
    "subtask015_mctaco_question_generation_frequency.json",
    "subtask016_mctaco_answer_generation_frequency.json",
    "subtask017_mctaco_wrong_answer_generation_frequency.json",
    "subtask018_mctaco_temporal_reasoning_presence.json",
    "subtask019_mctaco_temporal_reasoning_category.json",
    "subtask020_mctaco_span_based_question.json",
    "subtask021_mctaco_grammatical_logical.json",
    "subtask023_cosmosqa_question_generation.json",
    "subtask024_cosmosqa_answer_generation.json",
    "subtask025_cosmosqa_incorrect_answer_generation.json",
    "subtask026_drop_question_generation.json",
    "subtask027_drop_answer_type_generation.json",
    "subtask028_drop_answer_generation.json",
    "subtask029_winogrande_full_object.json",
    "subtask030_winogrande_full_person.json",
    "subtask031_winogrande_question_generation_object.json",
    "subtask032_winogrande_question_generation_person.json",
    "subtask035_winogrande_question_modification_person.json",
    "subtask036_qasc_topic_word_to_generate_related_fact.json",
    "subtask037_qasc_generate_related_fact.json",
    "subtask038_qasc_combined_fact.json",
    "subtask041_qasc_answer_generation.json",
    "subtask042_qasc_incorrect_option_generation.json",
    "subtask043_essential_terms_answering_incomplete_questions.json",
    "subtask046_miscellaenous_question_typing.json",
    "subtask047_misc_answering_science_questions.json",
    "subtask048_multirc_question_generation.json",
    "subtask049_multirc_questions_needed_to_answer.json",
    "subtask050_multirc_answerability.json",
    "subtask051_multirc_correct_answer_single_sentence.json",
    "subtask053_multirc_correct_bad_question.json",
    "subtask054_multirc_write_correct_answer.json",
    "subtask055_multirc_write_incorrect_answer.json",
    "subtask056_multirc_classify_correct_answer.json",
    "subtask057_multirc_classify_incorrect_answer.json",
    "subtask058_multirc_question_answering.json",
    "subtask059_ropes_story_generation4.json",
    "subtask060_ropes_question_generation4.json",
    "subtask061_ropes_answer_generation4.json"
  ],

  "val_tasks": [
    "subtask002_quoref_answer_generation.json",
    "subtask003_mctaco_question_generation_event_duration.json",
    "subtask005_mctaco_wrong_answer_generation_event_duration.json",
    "subtask008_mctaco_wrong_answer_generation_transient_stationary.json",
    "subtask022_cosmosqa_passage_inappropriate_binary.json",
    "subtask033_winogrande_answer_generation.json",
    "subtask034_winogrande_question_modification_object.json",
    "subtask039_qasc_find_overlapping_words.json",
    "subtask040_qasc_question_generation.json",
    "subtask044_essential_terms_identifying_essential_words.json",
    "subtask045_miscellaneous_sentence_paraphrasing.json",
    "subtask052_multirc_identify_bad_question.json"
  ],

  "template": "./natural_instructions_v1_template.txt",
  "pos_template": "./natural_instructions_v1_positive_examples_template.txt",
  "neg_template": "./natural_instructions_v1_negative_examples_template.txt",

  "max_input_length": 1024,
  "max_output_length": 128,
  "batch_size": 32,
  "eval_batch_size": 8,
  "gradient_accumulation_steps": 4,
  "weight_decay": 0.01,
  "max_lr": 0.00002,
  "min_lr": 0.0000002,
  "cycle_steps": 5000,
  "warmup_steps": 500,
  "lr_gamma": 0.8,

  "num_epochs": 5,
  "eval_very_n_steps": 1500,

  "fp16": true,
  "compile": true,
  "activation_checkpointing": false,

  "seed": 456970,
  "device": "cuda",
  "num_workers": 2
}
